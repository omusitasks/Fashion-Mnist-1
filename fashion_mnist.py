# -*- coding: utf-8 -*-
"""Fashion-mnist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/Waleed-Mujahid/Fashion-mnist/blob/main/Fashion_mnist.ipynb

# Comparison of KNN, Single layer NN and CNN using Fashion-mnist

In this committee notebook I will be using the Fashion mnist dataset to carry out a comparison between K nearest neighbours, a Single-layered neural network and a Convulotional neural network

## Importing Dependecies
We start off by import the neccesary libraries.
"""

import tensorflow as tf
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import keras
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

"""## Loading our Dataset
Next up we load our dataset using Tensorflow's dataset repository
"""

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()

# Let us take a look at the datatype of the dataset
print(type(x_train))

"""So we have an N dimensional numpy array.

---

Now lets look at the shape of Train and Test datasets
"""

print(x_train.shape, x_test.shape)

img_size = x_train.shape[1]

"""We need a 2d numpy array to apply K nearest Neighbours classifier so we reshape our dataset."""

x_train = x_train.reshape((x_train.shape[0],-1))
x_test = x_test.reshape((x_test.shape[0],-1))

print(x_train.shape, x_test.shape)

print(y_train.shape)

"""**Point to be noted:** Our labels are not one hot encoded


---
 We get the class labels from the meta-deta about the dataset

"""

class_labels = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneakers','Bag','Ankle boot']

"""## K Nearest Neighbour Model
### Pre-processing our Data
First we normalize our data using Sklearn pre-processing
"""

from sklearn.preprocessing import Normalizer
norm = Normalizer()

x_train_norm = norm.fit_transform(x_train)
x_test_norm = norm.transform(x_test)

"""**Note:** We fit the normalizer on only the train data so we do not face any overfitting. Transform is done on both as it normalizes the data while fit calculates average and standard deviation.

---

Next we use Sklearn's K nearest neighbours to classify the data

### Training the Model
We use Sklearn's build in K neighbours Classifier to train the data.
"""

from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier()
classifier.fit(x_train_norm,y_train)

"""### Evalutaing the Model
Next we make use of Sklearn.metrics to check how the K neighbours classifier is performing
"""

from sklearn.metrics import accuracy_score
y_pred = classifier.predict(x_test_norm)
KNN_accuracy = accuracy_score(y_test,y_pred)

print(f'So the accuracy for N nearest neighbours is {KNN_accuracy*100} ')

from sklearn.metrics import f1_score, precision_score, recall_score
KNN_f1_score = f1_score(y_test,y_pred, average = 'weighted')
KNN_precision_score = precision_score(y_test,y_pred, average = 'weighted')
KNN_recall_score = f1_score(y_test,y_pred, average = 'weighted')

print(f'F1 score = {KNN_f1_score*100:.02f} \nPrecision = {KNN_precision_score*100:.02f} \nRecall = {KNN_recall_score*100:.02f}')

"""### Plotting confusion Matrix"""

params = {'figure.figsize': (16, 9)}
plt.rcParams.update(params)

from sklearn.metrics import confusion_matrix
cm1 = confusion_matrix(y_test,y_pred, normalize='true')

from sklearn.metrics import ConfusionMatrixDisplay
disp = ConfusionMatrixDisplay(cm1*100, display_labels=class_labels)
disp.plot()

"""**Note:**
The confusion matrix has a lot of information. One particular thing to be noted is Shirt was correctly predicted only 57% times. It is due to the fact that Shirt is quite similar to a T-shirp/top , pullover and coat as well. Shirts are misidentified as these items which leads to a lower accuracy for shirt. We will see in the CNN model this accuracy will increase.

## Importing helper functions
Next up I import some helper functions to avoid rewriting code.
"""

!wget https://raw.githubusercontent.com/Waleed-Mujahid/Coding/master/colabUtils.py

from colabUtils import *

"""## Single Layer Neural Network
Now we will create a neural network with only one hidden layer and fit our data to it.

### Building our Neural Network
"""

model = Sequential()
model.add(Dense(512, input_shape = x_train_norm[0].shape , activation = 'relu'))
model.add(Dense(10, activation = 'softmax'))

model.summary()

"""### Fitting the model on Data"""

model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,
optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
metrics=['accuracy'])

history = model.fit(x_train_norm, y_train, validation_split=0.1, epochs = 20)

"""now lets take a look at home our model trained"""

plotAccuracy(history,True)

"""### Evaluating the Model"""

loss, accuracy_nn = model.evaluate(x_test_norm,y_test)

print(f"The accuracy received on Test data is: {accuracy_nn*100:.2f}%")

from sklearn.metrics import f1_score, precision_score, recall_score

y_pred2 = model.predict(x_test_norm)
y_pred2 = np.argmax(y_pred2, axis=1)
NN_f1_score = f1_score(y_test,y_pred2, average = 'weighted')
NN_precision_score = precision_score(y_test,y_pred2, average = 'weighted')
NN_recall_score = f1_score(y_test,y_pred2, average = 'weighted')

print(f'F1 score = {NN_f1_score*100:.02f} \nPrecision = {NN_precision_score*100:.02f} \nRecall = {NN_recall_score*100:.02f}')

"""### Plotting a Confusion Matrix"""

from sklearn.metrics import confusion_matrix
cm2 = confusion_matrix(y_test,y_pred2, normalize='true')

from sklearn.metrics import ConfusionMatrixDisplay
disp = ConfusionMatrixDisplay(cm2*100, display_labels=class_labels)
disp.plot()

"""Here we can note that the accuracy for shirt is still poor.

## Convulotional Neural Network

First we resize our data bach into 2d images as it is a requirement for Conv layers.
"""

x_train_norm = x_train_norm.reshape(x_train_norm.shape[0],img_size,img_size)
x_test_norm = x_test_norm.reshape(x_test_norm.shape[0],img_size,img_size)

print(x_train_norm.shape,x_test_norm.shape)
print(y_train.shape)

"""### Building our CNN"""

model2 = Sequential()
model2.add(Conv2D(32, (5, 5), padding = 'same' , input_shape=(img_size,img_size,1)))  # Input size of all images must be standard for model
model2.add(keras.layers.Activation('relu'))
model2.add(Conv2D(32, (5, 5), padding = 'same'))
model2.add(keras.layers.Activation('relu'))
model2.add(MaxPooling2D(strides=2))
model2.add(Dropout(0.4))

model2.add(Conv2D(64, (5, 5) , padding = 'same'))
model2.add(keras.layers.Activation('relu'))
model2.add(Conv2D(64, (5, 5) , padding = 'same'))
model2.add(keras.layers.Activation('relu'))
model2.add(MaxPooling2D(strides=2))
model2.add(Dropout(0.4))

model2.add(Conv2D(128, (3, 3) , padding = 'same'))
model2.add(keras.layers.Activation('relu'))
model2.add(Conv2D(128, (3, 3) , padding = 'same'))
model2.add(keras.layers.Activation('relu'))
model2.add(MaxPooling2D(strides=2))
model2.add(Dropout(0.4))


model2.add(Flatten())
model2.add(Dense(10, activation='softmax')) 

model2.summary()

"""### Fitting our CNN"""

model2.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,
optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
metrics=['accuracy'])

history2 = model2.fit(x_train_norm, y_train, validation_split=0.1, epochs = 20)

"""Now lets take a look at how our model trained."""

plotAccuracy(history2,True)

"""### Evaluating our CNN"""

loss_cnn, accuracy_cnn = model2.evaluate(x_test_norm,y_test)

print(f"The accuracy received on Test data is: {accuracy_cnn*100:.2f}%")

from sklearn.metrics import f1_score, precision_score, recall_score

y_pred3 = model2.predict(x_test_norm)
y_pred3 = np.argmax(y_pred3, axis=1)
CNN_f1_score = f1_score(y_test,y_pred3, average = 'weighted')
CNN_precision_score = precision_score(y_test,y_pred3, average = 'weighted')
CNN_recall_score = f1_score(y_test,y_pred3, average = 'weighted')

print(f'F1 score = {CNN_f1_score*100:.02f} \nPrecision = {CNN_precision_score*100:.02f} \nRecall = {CNN_recall_score*100:.02f}')

"""Plotting a Confusion Matrix"""

from sklearn.metrics import confusion_matrix
cm3 = confusion_matrix(y_test,y_pred3, normalize='true')

from sklearn.metrics import ConfusionMatrixDisplay
disp = ConfusionMatrixDisplay(cm3*100, display_labels=class_labels)
disp.plot()

"""Here we can note that the accuracy of shirt has increase from 57 to 74 by using a convolutional neural network. This is due to the fact that convulotional neural networks are great for finding patterns in images. This is also why we got highest accuracy and F1 score for the CNN model."""

accuracy = [KNN_accuracy,accuracy_nn,accuracy_cnn]
precision = [KNN_precision_score,NN_precision_score,CNN_precision_score]
recall = [KNN_recall_score,NN_recall_score,CNN_recall_score]
f1_score = [KNN_f1_score,NN_f1_score,CNN_f1_score]
x = ['K Nearest Neighbors',"Single layer NN", "CNN"]
from pylab import rcParams
rcParams['figure.figsize'] = 12, 6
fig, ax = plt.subplots()
ax.plot(x,accuracy)
ax.plot(x,precision)
ax.plot(x,recall)
ax.plot(x,f1_score)
ax.set_xticks(x)
plt.xlabel("Type of model used", fontsize = 16)
plt.ylabel("Accuracy of model", fontsize = 16)
plt.legend(['Accuracy', 'Precision', 'Recall', 'F1_score'], loc='upper left')
plt.title("Accuracy of various models for Fashion mnist Data", fontsize = 20)
plt.show()

"""Above graph demonstrates how using a Neural network is  better for image classification and how adding Convulotional layers to our neural network can boost our model's accuracy."""